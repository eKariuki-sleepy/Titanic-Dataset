{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_columns = 100\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "%matplotlib inline\n",
    "from scipy.stats import chi2_contingency\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autolabel(arrayA):\n",
    "    ''' label each colored square with the corresponding data value. \n",
    "    If value > 20, the text is in black, else in white.\n",
    "    '''\n",
    "    arrayA = np.array(arrayA)\n",
    "    for i in range(arrayA.shape[0]):\n",
    "        for j in range(arrayA.shape[1]):\n",
    "                plt.text(j,i, \"%.2f\"%arrayA[i,j], ha='center', va='bottom',color='w')\n",
    "\n",
    "def hist_it(feat):\n",
    "    plt.figure(figsize=(16,4))\n",
    "    feat[Y==0].hist(bins=range(int(feat.min()),int(feat.max()+2)),normed=True,alpha=0.8)\n",
    "    feat[Y==1].hist(bins=range(int(feat.min()),int(feat.max()+2)),normed=True,alpha=0.5)\n",
    "    plt.ylim((0,1))\n",
    "    \n",
    "def gt_matrix(feats,sz=16):\n",
    "    a = []\n",
    "    for i,c1 in enumerate(feats):\n",
    "        b = [] \n",
    "        for j,c2 in enumerate(feats):\n",
    "            mask = (~train[c1].isnull()) & (~train[c2].isnull())\n",
    "            if i>=j:\n",
    "                b.append((train.loc[mask,c1].values>=train.loc[mask,c2].values).mean())\n",
    "            else:\n",
    "                b.append((train.loc[mask,c1].values>train.loc[mask,c2].values).mean())\n",
    "\n",
    "        a.append(b)\n",
    "\n",
    "    plt.figure(figsize = (sz,sz))\n",
    "    plt.imshow(a, interpolation = 'None')\n",
    "    _ = plt.xticks(range(len(feats)),feats,rotation = 90)\n",
    "    _ = plt.yticks(range(len(feats)),feats,rotation = 0)\n",
    "    autolabel(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv',index_col = 0)\n",
    "y = train.Survived\n",
    "test = pd.read_csv('data/test.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns = [c.lower() for c in train.columns]\n",
    "test.columns = [c.lower() for c in test.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330877</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson, Master. Gosta Leonard</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>347742</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>237736</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             survived  pclass  \\\n",
       "PassengerId                     \n",
       "1                   0       3   \n",
       "2                   1       1   \n",
       "3                   1       3   \n",
       "4                   1       1   \n",
       "5                   0       3   \n",
       "6                   0       3   \n",
       "7                   0       1   \n",
       "8                   0       3   \n",
       "9                   1       3   \n",
       "10                  1       2   \n",
       "\n",
       "                                                          name     sex   age  \\\n",
       "PassengerId                                                                    \n",
       "1                                      Braund, Mr. Owen Harris    male  22.0   \n",
       "2            Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n",
       "3                                       Heikkinen, Miss. Laina  female  26.0   \n",
       "4                 Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0   \n",
       "5                                     Allen, Mr. William Henry    male  35.0   \n",
       "6                                             Moran, Mr. James    male   NaN   \n",
       "7                                      McCarthy, Mr. Timothy J    male  54.0   \n",
       "8                               Palsson, Master. Gosta Leonard    male   2.0   \n",
       "9            Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.0   \n",
       "10                         Nasser, Mrs. Nicholas (Adele Achem)  female  14.0   \n",
       "\n",
       "             sibsp  parch            ticket     fare cabin embarked  \n",
       "PassengerId                                                          \n",
       "1                1      0         A/5 21171   7.2500   NaN        S  \n",
       "2                1      0          PC 17599  71.2833   C85        C  \n",
       "3                0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "4                1      0            113803  53.1000  C123        S  \n",
       "5                0      0            373450   8.0500   NaN        S  \n",
       "6                0      0            330877   8.4583   NaN        Q  \n",
       "7                0      0             17463  51.8625   E46        S  \n",
       "8                3      1            349909  21.0750   NaN        S  \n",
       "9                0      2            347742  11.1333   NaN        S  \n",
       "10               1      0            237736  30.0708   NaN        C  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 11)\n",
      "(418, 10)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 1 to 891\n",
      "Data columns (total 11 columns):\n",
      "survived    891 non-null int64\n",
      "pclass      891 non-null int64\n",
      "name        891 non-null object\n",
      "sex         891 non-null object\n",
      "age         714 non-null float64\n",
      "sibsp       891 non-null int64\n",
      "parch       891 non-null int64\n",
      "ticket      891 non-null object\n",
      "fare        891 non-null float64\n",
      "cabin       204 non-null object\n",
      "embarked    889 non-null object\n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 83.5+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId\n",
       "1     1\n",
       "2     0\n",
       "3     1\n",
       "4     0\n",
       "5     1\n",
       "6     2\n",
       "7     0\n",
       "8     1\n",
       "9     1\n",
       "10    1\n",
       "11    0\n",
       "12    0\n",
       "13    1\n",
       "14    1\n",
       "15    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check for NaN values first by row then by column\n",
    "train.isnull().sum(axis=1).head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "survived      0\n",
       "pclass        0\n",
       "name          0\n",
       "sex           0\n",
       "age         177\n",
       "sibsp         0\n",
       "parch         0\n",
       "ticket        0\n",
       "fare          0\n",
       "cabin       687\n",
       "embarked      2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of NaNs for each column\n",
    "train.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset cleaning and other things to check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remove constant features**\n",
    "<br>We will now try to clean the dataset. It is usually convenient to concatenate train and test into one dataframe and do all feature engineering using\n",
    "<br> However, remeber that the test set usually we don't know anything about it and we should absorb any info from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[:,df.apply(pd.Series.nunique) != 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicated features, first I create a copy of my dataframe as it label encode all the categorical data\n",
    "# if though the two columns has NaN values at the same posisiton it is still working\n",
    "train1 = train.copy()\n",
    "#train1['no'] = train1.sex.apply(lambda x: 'male' if x=='female' else 'female')\n",
    "#train1.loc[5,'no'] =np.nan\n",
    "#train1.loc[5,'sex'] =np.nan\n",
    "print(train1.shape)\n",
    "# For categorical values\n",
    "for f in train1.select_dtypes(include=[object]).columns:\n",
    "    train1[f] = train1[f].factorize()[0]\n",
    "# For numeric features\n",
    "train1 = train1.T.drop_duplicates().T\n",
    "train1.shape,train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nunique = train.nunique(dropna=False)\n",
    "nunique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a normalized histogram of those values\n",
    "plt.figure(figsize=(14,6))\n",
    "_ = plt.hist(nunique.astype(float)/train.shape[0], bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (nunique.astype(float)/train.shape[0] > 0.7)\n",
    "train.loc[:10, mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (nunique.astype(float)/train.shape[0] < 0.8) & (nunique.astype(float)/train.shape[0] > 0.4)\n",
    "train.loc[:10, mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#It is useful to check some features that looks suspicious\n",
    "mask = (nunique.astype(float)/train.shape[0] < 0.8) & (nunique.astype(float)/train.shape[0] > 0.4)\n",
    "train['ticket'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the features into categorical and numerical\n",
    "cat_cols = list(train.select_dtypes(include=['object']).columns)\n",
    "num_cols = list(train.select_dtypes(exclude=['object']).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We replace NaN with a value -999\n",
    "train.replace('NaN', -999, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's calculate how many times one feature is greater than the other and create cross tabel out of it.\n",
    "# select first 42 numeric features\n",
    "feats = num_cols[:42]\n",
    "\n",
    "# build 'mean(feat1 > feat2)' plot\n",
    "gt_matrix(feats,16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could hve found that every second feature is greater, not to the second but let's say i+1 feature is greater than the feature i. And, well it could be that this information is about, for example, counters in different periods of time. So, for example, the first feature is how many events happened in the first month. The second feature is how many events happened in the first two month and so kind of cumulative values. And, that is why one feature is always greater than the other. And basically, what information we can extract from this kind of metrics is that we have this group and we can generate new features and these features could be, for example, the difference between two consecutive features. That is how we will extract, for example, the number of events in each month. So, we'll go from cumulative values back to normal values. And, well linear models, say, neural networks, they could do it themselves but tree-based algorithms they could not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram of features\n",
    "sns.distplot(train['fare'],bins=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we notice consecutive peaks and by running value_counts we see that it has a lot of counts on 12,24,36.. we could crete a feature modulo 12There's something in there. We will see that the values, the top values, are 12, 24, 36, 60 and so on. So, they can be divided by 12 and well, and what can we do? We want to generate features so we will generate feature like the value of these variable modular 12 or, for example, value of this variable integer division by 12. So, this could really help. In other competition, you could build a variable and see something like that again. And what happened in there, the organizers actually had quantized data. So, they only had data that in our case could be divided by 12. Say 12, 24 and so on. But, they wanted to kind of obfuscate the data probably and they added some noise. And, that is why if you plot an histogram, you will still see the spikes but you will also see something in between the spikes. And so, again, these features in that competition they work quite well and you could dequantize the values and it could really help."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if dataset is shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-fb8f992170b0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msurvived\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrolling\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwindow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_periods\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Rolling Mean'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Index'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfontsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'x-large'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Survived'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfontsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'x-large'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxhline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msurvived\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlinestyle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'--'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Mean'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize= [15,6])\n",
    "plt.plot(train.index,train.survived.rolling(window=5, min_periods=1).mean(),label='Rolling Mean')\n",
    "plt.xlabel('Index',fontsize='x-large')\n",
    "plt.ylabel('Survived',fontsize='x-large')\n",
    "plt.axhline(y= train.survived.mean(), color='r', linestyle='--',label='Mean')\n",
    "plt.legend(loc='best',framealpha=.9, fontsize='large')\n",
    "plt.xlim([-10,900])\n",
    "plt.title('Check if dataset is shuffled',fontsize='xx-large')\n",
    "ax = fig.gca()\n",
    "ax.set_xticks(numpy.arange(0, 31, 1))\n",
    "ax.set_yticks(numpy.arange(0, 31., 1))\n",
    "plt.scatter(x, y)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# tickets starting with\n",
    "train.Ticket.apply(lambda x: x[0]).value_counts()[0:5]\n",
    "for i in [1,2,3]:\n",
    "    train['ticket_on_'+str(i)] = train.Ticket.apply(lambda x: 1 if x[0]==i else 0)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_matrix = pd.scatter_matrix(\n",
    "    train,\n",
    "    figsize  = [15, 15],\n",
    "    #marker   = \".\",\n",
    "    #s        = 0.2,\n",
    "    #diagonal = \"kde\"\n",
    ")\n",
    "\n",
    "for ax in scatter_matrix.ravel():\n",
    "    ax.set_xlabel(ax.get_xlabel(), fontsize = 20, rotation = 90)\n",
    "    ax.set_ylabel(ax.get_ylabel(), fontsize = 20, rotation = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(train.corr(),linewidths=.5,cmap=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = train.mean().sort_values().plot(style='.')\n",
    "ax.set_xticks(range(0,6))\n",
    "ax.set_xticklabels(train.mean().sort_values().index, rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.select_dtypes(exclude=[object]).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig , ax = plt.subplots(figsize=(6,4))\n",
    "sns.countplot(x='survived', data=train)\n",
    "plt.title(\"Count of Survival\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's find correlation between Numeric Variable\n",
    "cat = train.drop(columns='survived').loc[:, train.dtypes == object].columns\n",
    "num = train.drop(columns='survived').loc[:, train.dtypes != object].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df=train[num]  #New dataframe to calculate correlation between numeric features\n",
    "cor= corr_df.corr(method='pearson')\n",
    "\n",
    "fig, ax =plt.subplots(figsize=(8, 6))\n",
    "plt.title(\"Correlation Plot\")\n",
    "sns.heatmap(cor, mask=np.zeros_like(cor, dtype=np.bool), cmap=sns.diverging_palette(220, 10, as_cmap=True),\n",
    "            square=True, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's use chi-square test to understand relationship between categorical variables and target variable\n",
    "csq=chi2_contingency(pd.crosstab(train['survived'], train['sex']))\n",
    "print(\"P-value: \",csq[1])\n",
    "csq2=chi2_contingency(pd.crosstab(train['survived'], train['embarked']))\n",
    "print(\"P-value: \",csq2[1])\n",
    "csq3=chi2_contingency(pd.crosstab(train['survived'], train['pclass']))\n",
    "print(\"P-value: \",csq3[1])\n",
    "\n",
    "# P values for features Sex, Embarked and Pclass are very low. So we can reject our Null Hypothesis which is these features\n",
    "# are independent and have no relationship with target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visulaization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax=plt.subplots(figsize=(8,6))\n",
    "sns.countplot(x='survived', data=train, hue='sex')\n",
    "ax.set_ylim(0,500)\n",
    "plt.title(\"Impact of Sex on Survived\")\n",
    "#We can say that Female passangers have higher probability of survival than Male passangers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax=plt.subplots(figsize=(8,6))\n",
    "sns.countplot(x='survived', data=train, hue='embarked')\n",
    "ax.set_ylim(0,500)\n",
    "plt.title(\"Impact of Embarked on Survived\")\n",
    "# Ratio of Survived and Not Survived passangers for S and Q Embarked are similar but Passengers from C\n",
    "# embarked have higer chances of survival."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax=plt.subplots(figsize=(8,6))\n",
    "sns.countplot(x='survived', data=train, hue='pclass')\n",
    "ax.set_ylim(0,400)\n",
    "plt.title(\"Impact of Pclass on Survived\")\n",
    "\n",
    "# Passengers from Pclass 3 have lesser chances of Survival while passengers from Pclass 1 have higher chances of survival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax=plt.subplots(1,figsize=(8,6))\n",
    "sns.boxplot(x='survived',y='fare', data=train)\n",
    "ax.set_ylim(0,300)\n",
    "plt.title(\"Survived vs Fare\")\n",
    "\n",
    "#Average Fare for passangers who survived is higher than not survived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.pclass = train.pclass.astype('str')\n",
    "print(train.pclass.value_counts())\n",
    "print(train.sex.value_counts())\n",
    "# So pclass & sex need One-hot Encoded\n",
    "# train = pd.get_dummies(train, columns =['pclass', 'sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.embarked.fillna(train.embarked.value_counts().idxmax(), inplace = True)\n",
    "test.embarked.fillna(train.embarked.value_counts().idxmax(), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.name = train.name.apply(lambda x: x.lower())\n",
    "test.name = test.name.apply(lambda x: x.lower())\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Title from Name, store in column and plot barplot\n",
    "train['title'] = train.name.apply(lambda x: re.search('([a-z]+)\\.', x).group(1))\n",
    "test['title'] = test.name.apply(lambda x: re.search('([a-z]+)\\.', x).group(1))\n",
    "sns.countplot(x='title', data=train);\n",
    "plt.xticks(rotation=45);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['title'] = train['title'].replace({'mille':'miss', 'mme':'mrs', 'ms':'miss'})\n",
    "test['title'] = test['title'].replace({'mille':'miss', 'mme':'mrs', 'ms':'miss'})\n",
    "l = ['mr','mrs','miss','master','dr']\n",
    "train.title = train.title.apply(lambda x: 'others' if x not in l else x)\n",
    "test.title = test.title.apply(lambda x: 'others' if x not in l else x)\n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.get_dummies(train, columns =['pclass', 'sex', 'embarked','title'])\n",
    "test = pd.get_dummies(test, columns =['pclass', 'sex', 'embarked','title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(columns =['name'], inplace=True)\n",
    "test.drop(columns =['name'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['no_cabin'] = train.cabin.isnull().astype(int)\n",
    "train.drop(columns =['cabin'], inplace=True)\n",
    "test['no_cabin'] = test.cabin.isnull().astype(int)\n",
    "test.drop(columns =['cabin'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['ticket2'] = train.ticket.astype('category').cat.codes\n",
    "test['ticket2'] = test.ticket.astype('category').cat.codes\n",
    "#train.drop(columns =['ticket'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.age.fillna(train.age.median(),inplace=True)\n",
    "test.age.fillna(train.age.median(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = train.groupby('ticket2')['ticket2'].count()/len(train)\n",
    "train['ticket3'] = train.ticket2.apply(lambda x: l[x])\n",
    "train.drop(columns=['ticket','ticket2'],inplace=True)\n",
    "train['family_mem']=train.apply(lambda x: x['sibsp']+x['parch'], axis=1)\n",
    "l = test.groupby('ticket2')['ticket2'].count()/len(test)\n",
    "test['ticket3'] = test.ticket2.apply(lambda x: l[x])\n",
    "test.drop(columns=['ticket','ticket2'],inplace=True)\n",
    "test['family_mem']=test.apply(lambda x: x['sibsp']+x['parch'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train.drop(columns='survived'), train.survived, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape,train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "dep = np.arange(1,9)\n",
    "param_grid = {'max_depth' : dep,'criterion':['gini','entropy']}\n",
    "\n",
    "# Instantiate a decision tree classifier: clf\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Instantiate the GridSearchCV object: clf_cv\n",
    "clf_cv = GridSearchCV(clf, param_grid=param_grid, cv=5)\n",
    "\n",
    "# Fit it to the data\n",
    "clf_cv.fit(X_train, y_train)\n",
    "\n",
    "# Print the tuned parameter and score\n",
    "print(\"Tuned Decision Tree Parameters: {}\".format(clf_cv.best_params_))\n",
    "print(\"Best score is {}\".format(clf_cv.best_score_))\n",
    "print(\"Test score is {}\".format(clf_cv.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = test.copy() # before becoming an array due to the scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit with all the training data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = train.drop(columns='survived')\n",
    "y_train = train.survived\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "test1.fare.fillna(test1.fare.median(),inplace=True)\n",
    "test1 = scaler.transform(test1)\n",
    "# Instantiate a decision tree classifier: clf\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Instantiate the GridSearchCV object: clf_cv\n",
    "clf_cv = GridSearchCV(clf, param_grid=param_grid, cv=5)\n",
    "\n",
    "# Fit it to the data\n",
    "clf_cv.fit(X_train, y_train)\n",
    "predictions = clf_cv.predict(test1)\n",
    "submission = pd.DataFrame({ 'PassengerId': test.index,\n",
    "                            'Survived': predictions })\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "rfc=RandomForestClassifier(random_state=42)\n",
    "param_grid = { \n",
    "    'n_estimators': [100, 150, 200],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth' : [3,4,5,6,7,8]}\n",
    "    #'criterion' :['gini', 'entropy']\n",
    "\n",
    "rfc_cv = RandomizedSearchCV(estimator=rfc, param_distributions=param_grid, cv= 5, n_iter=5)\n",
    "rfc_cv.fit(X_train, y_train)\n",
    "\n",
    "# Print the tuned parameter and score\n",
    "print(\"Tuned Decision Tree Parameters: {}\".format(rfc_cv.best_params_))\n",
    "print(\"Best score is {}\".format(rfc_cv.best_score_))\n",
    "print(\"Test score is {}\".format(rfc_cv.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost.sklearn import XGBClassifier \n",
    "import scipy.stats as st\n",
    "\n",
    "one_to_left = st.beta(10, 1)  \n",
    "from_zero_positive = st.expon(0, 50)\n",
    "\n",
    "params = {  \n",
    "    \"n_estimators\": st.randint(50, 200),\n",
    "    \"max_depth\": st.randint(3, 15),\n",
    "    \"learning_rate\": st.uniform(0.05, 0.4),\n",
    "    \"colsample_bytree\": one_to_left,\n",
    "    \"subsample\": one_to_left,\n",
    "    \"gamma\": st.uniform(0, 10),\n",
    "    'reg_alpha': from_zero_positive,\n",
    "    \"min_child_weight\": from_zero_positive,\n",
    "}\n",
    "\n",
    "xgb = XGBClassifier()  \n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "gs = RandomizedSearchCV(xgb, params,cv= 5, n_iter=15,scoring = 'accuracy', n_jobs=-1)  \n",
    "gs.fit(X_train, y_train)  \n",
    "\n",
    "# Print the tuned parameter and score\n",
    "print(\"Tuned Decision Tree Parameters: {}\".format(gs.best_params_))\n",
    "print(\"Best score is {}\".format(gs.best_score_))\n",
    "print(\"Test score is {}\".format(gs.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost.sklearn import XGBClassifier \n",
    "import scipy.stats as st\n",
    "\n",
    "xgb = XGBClassifier()  \n",
    "\n",
    "gs = xgb.fit(X_train, y_train)  \n",
    "\n",
    "y_pred = gs.predict(X_test)\n",
    "\n",
    "# Print the tuned parameter and score\n",
    "print(\"Test score is {}\".format(gs.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['predicted'] = y_pred\n",
    "df.rename(columns={'survived':'true'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_different'] = np.abs(df.predicted - df.true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mistakes = df.query('is_different==1').index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = df.query('is_different==0').index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test.loc[correct].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.loc[mistakes].describe()\n",
    "#len(mistakes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = pd.DataFrame(X_test.columns)\n",
    "importances.rename(columns={0:'feature'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances['importance'] = pd.Series(gs.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances.sort_values('importance',ascending=False).set_index('feature').plot(kind='bar',figsize=(15,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('data/test.csv')\n",
    "pred = gs.predict(test)\n",
    "submission = pd.DataFrame({ 'PassengerId': test['PassengerId'],\n",
    "                            'Survived': df.predicted })\n",
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script shows you how to make a submission using a few\n",
    "# useful Python libraries.\n",
    "# It gets a public leaderboard score of 0.76077.\n",
    "# Maybe you can tweak it and do better...?\n",
    "\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "# Load the data\n",
    "train_df = pd.read_csv('../input/train.csv', header=0)\n",
    "test_df = pd.read_csv('../input/test.csv', header=0)\n",
    "\n",
    "# We'll impute missing values using the median for numeric columns and the most\n",
    "# common value for string columns.\n",
    "# This is based on some nice code by 'sveitser' at http://stackoverflow.com/a/25562948\n",
    "from sklearn.base import TransformerMixin\n",
    "class DataFrameImputer(TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        self.fill = pd.Series([X[c].value_counts().index[0]\n",
    "            if X[c].dtype == np.dtype('O') else X[c].median() for c in X],\n",
    "            index=X.columns)\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        return X.fillna(self.fill)\n",
    "\n",
    "feature_columns_to_use = ['Pclass','Sex','Age','Fare','Parch']\n",
    "nonnumeric_columns = ['Sex']\n",
    "\n",
    "# Join the features from train and test together before imputing missing values,\n",
    "# in case their distribution is slightly different\n",
    "big_X = train_df[feature_columns_to_use].append(test_df[feature_columns_to_use])\n",
    "big_X_imputed = DataFrameImputer().fit_transform(big_X)\n",
    "\n",
    "# XGBoost doesn't (yet) handle categorical features automatically, so we need to change\n",
    "# them to columns of integer values.\n",
    "# See http://scikit-learn.org/stable/modules/preprocessing.html#preprocessing for more\n",
    "# details and options\n",
    "le = LabelEncoder()\n",
    "for feature in nonnumeric_columns:\n",
    "    big_X_imputed[feature] = le.fit_transform(big_X_imputed[feature])\n",
    "\n",
    "# Prepare the inputs for the model\n",
    "train_X = big_X_imputed[0:train_df.shape[0]].as_matrix()\n",
    "test_X = big_X_imputed[train_df.shape[0]::].as_matrix()\n",
    "train_y = train_df['Survived']\n",
    "\n",
    "# You can experiment with many other options here, using the same .fit() and .predict()\n",
    "# methods; see http://scikit-learn.org\n",
    "# This example uses the current build of XGBoost, from https://github.com/dmlc/xgboost\n",
    "gbm = xgb.XGBClassifier(max_depth=3, n_estimators=300, learning_rate=0.05).fit(train_X, train_y)\n",
    "predictions = gbm.predict(test_X)\n",
    "\n",
    "# Kaggle needs the submission to have a certain format;\n",
    "# see https://www.kaggle.com/c/titanic-gettingStarted/download/gendermodel.csv\n",
    "# for an example of what it's supposed to look like.\n",
    "submission = pd.DataFrame({ 'PassengerId': test_df['PassengerId'],\n",
    "                            'Survived': predictions })\n",
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
